{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load text\n",
    "with open(\"../datasets/text_for_processing.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Create DataFrames\n",
    "df_stemming = pd.DataFrame({\"Original Word\": words, \"Stemmed Word\": stemmed_words})\n",
    "df_lemmatization = pd.DataFrame({\"Original Word\": words, \"Lemmatized Word\": lemmatized_words})\n",
    "\n",
    "# Save results\n",
    "df_stemming.to_csv(\"../datasets/stemming_result.csv\", index=False)\n",
    "df_lemmatization.to_csv(\"../datasets/lemmatization_result.csv\", index=False)\n",
    "\n",
    "# Display tables\n",
    "print(\"Stemming Results:\")\n",
    "display(df_stemming.head())\n",
    "\n",
    "print(\"Lemmatization Results:\")\n",
    "display(df_lemmatization.head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
